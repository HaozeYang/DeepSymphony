09152017
  finish most utility tools


09162017
  finish the first demo

  x sustain too long
    add limitation on sustain time
    > more diverse, have longer pattern

  x dive into slience (no 1 at all)
    randomize the input when slient
    > no slience 
  ===>0000.mid
> try stateful RNN but not aligned with one song when training
    > not good, all slience

  > change mse to binary_crossentropy
    much less confidence
    > use threshold==0.3
      > not bad, has rhythm ====> 0001.mid
      comes to slience and start again 
        > use note/=max strategy, not good ===> 0002.mid
      > add noise
        still slience but more diverse 0003.mid
      > use binomial random (1, 0.3) rather than uniform
        more diverse 0004.mid
      > use binomial random (1, 0.6)
        it got emotional sometimes LOL 0005.mid
      > use binomial random (1, 0.8)
        more keys, but in an aweful styel 0006.mid 

    ==> conclusion
      overfit on one tune, which is bad (or good?)

09172017
  retrain
    > got another rhythm, which keeps unchanged in the song 
       0007.mid
  activation from hard_sigmoid to sigmoid
    more diverse and proactive
       0008.mid
    some kind of magical realism
  fix accumulate bug:
    didn't set to zero after note off
  set noise after notes.append
  seq.append after noise is added
    
    wired repetition:
        0009.mid
    max_sus=4, noise=(0.5, 2.0)
        0010.mid
  less the binomial_p, sparser the notes
    max_sus=4, noise=(0.5, 2.0), random=binomial(1, 0.3)
        0011.mid
  notes too dense, raise threshold to 0.99
        0012.mid
        not good
  make the dense layers more complex, shorten the max_sus
	quite well 
		0013.mid
	set threshold to 0.50 to get cleaner version
		0014.mid
	remove the random reset to make the theme of song consistant
		0015.mid
	random->(1, 0.3)
		0016.mid
        can switch between rhythms
		0017.mid


09172017
   simple_rnn2
      overfit on one tune, 0018.mid
   simple structure
      32-LSTM -> 128 FC    0019.mid

09182017
   memorize
     hard to memorize the song
     stack on a rhythm     0020.mid
     keep repeating a most-frequent rhythms

   change to
     LSTM-100, Dense-50, Dense-128
     change remember longer rhythm, but still repeating 0021.mid
   
   add random decay in the generation
     random connection of pieces 0022.mid

09192017
  gan rnn1 (commit "gan rnn")
    cannot even learn the patter that most places are black
    stop converging after 500 
      d_loss converged to almost 0
      g_loss dispesed to 16 and the output remained unchange

  gan rnn2 (commit "gan conv")
    can learn which note is more frequently played than other, 
      but don't have inner patter (maybe the dataset is too small?)
      display/9900.png vs display/real.png

0922~0925
  Gcnn_Dcnnn
  Grnn_Drnn

0925~0928
  refactory the encoder
  encode again
  large dataset

  updated simple_rnn on e-comp (len=2000)
    0023.mid
  updated simple_rnn on esay (len=100)
    first one with rhythm: 0024.mid (loss=1.1757)
    0025.mid (loss=0.7159)
    0026.mid (loss=0.4621)
    0027.mid (loss=0.2543)
    0028.mid (loss=0.2166) plagirism?
    0029.mid (loss=0.2048, seed=32) plagirism?
    
    0031.mid (loss=0.3579, seed=32) data argument
    0032.mid favorite one 

0930
  tried all night
    e-comp-all, loss = 1.8979 (0033.mid)
      awesome
    e-comp-all, loss = 1.85  (0034.mid)
      long one, borrow



TODO:change model
    original:
                                    T5 
				    ^
       model -> model -> model -> model
         ^        ^        ^        ^  
	 T1       T2       T3       T4
    new one
    	 ?        ?        T3       T4
         ^        ^        ^        ^  
       model -> model -> model -> model
         ^        ^        ^        ^  
	 T1       T2       ?        ? 

TODO: remember
TODO: augment data by shifting 
TODO: left-hand right-hand


GAN
AE
